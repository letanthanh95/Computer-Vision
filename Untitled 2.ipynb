{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e72792-5122-4a63-b0cc-5511a838235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a86a60-0eca-4fc7-930a-8e9fa8a9601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(frame, template,MIN_MATCH_COUNT,MIN_AREA,MAX_AREA,TEMPLATE_MATCHING_THRESHOLD,AREA_TOLERANCE):\n",
    "    orb = cv2.ORB_create(nfeatures=5000)\n",
    "    kp1, des1 = orb.detectAndCompute(template, None)\n",
    "    kp2, des2 = orb.detectAndCompute(frame, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    if des1 is None or des2 is None or len(des1) == 0 or len(des2) == 0:\n",
    "        return None\n",
    "\n",
    "    if len(kp1) < 5 or len(kp2) < 5:\n",
    "        return None\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Only consider the top 75% matches\n",
    "    matches = matches[:int(len(matches) * 0.75)]\n",
    "    print('matches: ',len(matches))\n",
    "    if len(matches) > MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if M is not None:\n",
    "            h, w, _ = template.shape\n",
    "            pts = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "            rect = cv2.boundingRect(np.int32(dst))\n",
    "            x, y, w, h = rect\n",
    "            \n",
    "            # Check if bounding rectangle area is within expected range\n",
    "            area = w * h\n",
    "            print('area: ',area)\n",
    "            \n",
    "            if MIN_AREA <= area <= MAX_AREA:\n",
    "                # Also, run template matching to validate the location\n",
    "                result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "                _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "                print(max_val)\n",
    "                if max_val > TEMPLATE_MATCHING_THRESHOLD:\n",
    "                    tx, ty = max_loc\n",
    "                    print(abs(tx - x), abs(ty - y))\n",
    "                    if abs(tx - x) <= AREA_TOLERANCE and abs(ty - y) <= AREA_TOLERANCE:\n",
    "                           return x, y, w, h\n",
    "    print(\"========END=================\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78176bf-8787-4732-a6e7-e60e917704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_PATH = '/Users/thanhle/Desktop/pythonProject/Entrance test 2/Task 1/Input/Level 1.jpg'\n",
    "VIDEO_PATH = '/Users/thanhle/Desktop/pythonProject/Entrance test 2/Task 1/Videos/Video 2.mp4'\n",
    "OUTPUT_DIR = '/Users/thanhle/Desktop/pythonProject/output'\n",
    "\n",
    "template = cv2.imread(TEMPLATE_PATH)\n",
    "video = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_count = 0\n",
    "\n",
    "MIN_MATCH_COUNT = 100\n",
    "MIN_AREA = 5000  # adjust based on your object size\n",
    "MAX_AREA = 5000000  # adjust based on your object size\n",
    "TEMPLATE_MATCHING_THRESHOLD = 0.51\n",
    "AREA_TOLERANCE = 600  # tolerance in pixels for template matching location validation\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    result = feature_matching(frame, template,MIN_MATCH_COUNT,MIN_AREA,MAX_AREA,TEMPLATE_MATCHING_THRESHOLD,AREA_TOLERANCE)\n",
    "    if result:\n",
    "        x, y, w, h = result\n",
    "        frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        save_path = f\"{OUTPUT_DIR}/Video 2/Object X/Frame {frame_count}.jpg\"\n",
    "        cv2.imwrite(save_path, frame)\n",
    "        print(\"========SAVED=================\")\n",
    "    frame_count += 1\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63733d92-cbb2-4053-9d73-f8fc04ddc9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a890c-ba12-434c-a501-fb271b364ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
